{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsAPI     =    0b1ea46e336d40e1abc48f51e01c253a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_date             datetime64[ns, UTC]\n",
      "headline_text                         object\n",
      "description                           object\n",
      "headline_sentiment                     int64\n",
      "description_sentiment                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('testData.csv')\n",
    "\n",
    "# convert the publish_date column to datetime64\n",
    "df['publish_date'] = pd.to_datetime(df['publish_date'])\n",
    "\n",
    "# convert remaining cols to string\n",
    "df['headline_text'] = df['headline_text'].astype(str)\n",
    "df['description'] = df['description'].astype(str)\n",
    "\n",
    "\n",
    "headlines_df = df.copy()\n",
    "headlines_df['headline_sentiment'] = 0\n",
    "headlines_df['description_sentiment'] = 0\n",
    "# headlines_df['pos_sentiment'] = 0\n",
    "# headlines_df['neg_sentiment'] = 0\n",
    "\n",
    "print(headlines_df.dtypes)\n",
    "headlines_df.head()\n",
    "\n",
    "total_headlines = len(headlines_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x30cca4a60>, {})\n"
     ]
    }
   ],
   "source": [
    "valid_emotions = ['joy', 'others', 'surprise',\n",
    "                  'sadness', 'fear', 'anger', 'disgust']\n",
    "\n",
    "\n",
    "# emotions =  {\"joy\": 0, \"others\": 0, \"surprise\": 0, \n",
    "#              \"sadness\": 0, \"fear\": 0, \"anger\": 0, \"disgust\": 0,\n",
    "#              \"others\": 0}\n",
    "\n",
    "emotions = defaultdict(lambda: defaultdict(int))\n",
    "# emotions = defaultdict(int)\n",
    "\n",
    "# print(emotions.keys())\n",
    "# print(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc07641a17b43bba312a7299ca9ab14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcd1f8fe89845e99d715b005e8304a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4464a9cdce641e0a8faeb493c853c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63285a6236be48f5a4ab589c3efb9c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c1528ee05749d696e1183682614b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dafc2354321429d8742b4c6562c9fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cf2647c87a4c4db0e26c2fb428d70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd831949799646f88135d7bc353954d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a812bbd093bc45cdb456bb038f6f6d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdca0eef27144d081afc1c2b2c7a43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197db70f89bb40929ebec9317f1212d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d810818850744c0a987cdff11ab0b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4bd48e8ebc40da9c90da5233d966ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5a2572208c4b9cbf849f905d892d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99f8bb65ff8499f9f487559b116c749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06ea564d7904d2988447becb0d5a490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1191ca3eb382499d851d8b178451ac16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c658e4a70c24137988fd1aa70f6e956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentiments = defaultdict(lambda: defaultdict(int))\n",
    "sentiment_model = pipeline(\n",
    "    model=\"siebert/sentiment-roberta-large-english\")  # Use device 0 for GPU\n",
    "\n",
    "emotion_model = pipeline(\n",
    "    model=\"finiteautomata/bertweet-base-emotion-analysis\")\n",
    "\n",
    "keyword_ext_model = pipeline(\n",
    "    model=\"yanekyuk/bert-keyword-extractor\")\n",
    "\n",
    "keyword_senti_model = pipeline(\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Sentiments: 100%|██████████| 5/5 [00:01<00:00,  3.35headline/s]\n"
     ]
    }
   ],
   "source": [
    "## analyse headlines ##\n",
    "with tqdm(total=total_headlines, desc=\"Analysing Sentiments\", unit=\"headline\", dynamic_ncols=True) as pbar:\n",
    "    for idx in range(total_headlines):\n",
    "        row = headlines_df.iloc[idx]\n",
    "        headline = row['headline_text']\n",
    "        description = row['description']\n",
    "\n",
    "\n",
    "        result = sentiment_model(headline)\n",
    "        label = result[0]['label']\n",
    "\n",
    "        if label == 'POSITIVE':\n",
    "            headlines_df.at[idx, 'headline_sentiment'] = 1\n",
    "        elif label == 'NEGATIVE':\n",
    "            headlines_df.at[idx, 'headline_sentiment'] = -1\n",
    "\n",
    "        ## analyse description ##               \n",
    "        result = sentiment_model(description)\n",
    "        label = result[0]['label']\n",
    "\n",
    "        if label == 'POSITIVE':\n",
    "            headlines_df.at[idx, 'description_sentiment'] = 1\n",
    "        elif label == 'NEGATIVE':\n",
    "            headlines_df.at[idx, 'description_sentiment'] = -1\n",
    "        \n",
    "\n",
    "        ## analyse emotions ##\n",
    "            \n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Emotions:   0%|          | 0/5 [00:00<?, ?headline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'others', 'score': 0.9769518971443176}]\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'others'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m valid_emotions:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m         emotions[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'others'"
     ]
    }
   ],
   "source": [
    "## analyse emotions ##\n",
    "\n",
    "headlines = headlines_df['headline_text'].tolist()\n",
    "\n",
    "emotions = {}\n",
    "\n",
    "with tqdm(total=total_headlines, desc=\"Analysing Emotions\", unit=\"headline\", dynamic_ncols=True) as pbar:\n",
    "    for batch_start in range(0, total_headlines):\n",
    "        batch_headline = headlines[batch_start]\n",
    "        # sentiment_date = publish_dates[batch_start]\n",
    "        # sentiment_month = sentiment_date.replace(\n",
    "            # day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "        results = emotion_model(batch_headline)\n",
    "        print(results)\n",
    "\n",
    "        for result in results:\n",
    "            label = result['label']\n",
    "            if label in valid_emotions:\n",
    "                print(True)\n",
    "                emotions[label] += 1\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "# print(emotions)\n",
    "# print(emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>description</th>\n",
       "      <th>headline_sentiment</th>\n",
       "      <th>description_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-28 04:50:27+00:00</td>\n",
       "      <td>Elon Musk joins Trump Republicans to slam rumo...</td>\n",
       "      <td>Elon Musk joined Donald Trump and Republican c...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-28 00:10:36+00:00</td>\n",
       "      <td>Tesla battery explodes in Cary home after bein...</td>\n",
       "      <td>Tesla battery explodes in Cary home after bein...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-27 21:01:05+00:00</td>\n",
       "      <td>Here's why Biden's multi-billion-dollar EV cha...</td>\n",
       "      <td>By Will Kessler Daily Caller News Foundation T...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-27 17:30:00+00:00</td>\n",
       "      <td>Who wants to be a trillionaire': The game show...</td>\n",
       "      <td>A trillion dollars can purchase shares of all...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-27 16:00:00+00:00</td>\n",
       "      <td>ARGHHH FUCK THIS</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               publish_date  \\\n",
       "0 2024-01-28 04:50:27+00:00   \n",
       "1 2024-01-28 00:10:36+00:00   \n",
       "2 2024-01-27 21:01:05+00:00   \n",
       "3 2024-01-27 17:30:00+00:00   \n",
       "4 2024-01-27 16:00:00+00:00   \n",
       "\n",
       "                                       headline_text  \\\n",
       "0  Elon Musk joins Trump Republicans to slam rumo...   \n",
       "1  Tesla battery explodes in Cary home after bein...   \n",
       "2  Here's why Biden's multi-billion-dollar EV cha...   \n",
       "3  Who wants to be a trillionaire': The game show...   \n",
       "4                                   ARGHHH FUCK THIS   \n",
       "\n",
       "                                         description  headline_sentiment  \\\n",
       "0  Elon Musk joined Donald Trump and Republican c...                  -1   \n",
       "1  Tesla battery explodes in Cary home after bein...                  -1   \n",
       "2  By Will Kessler Daily Caller News Foundation T...                  -1   \n",
       "3   A trillion dollars can purchase shares of all...                   1   \n",
       "4                                               test                  -1   \n",
       "\n",
       "   description_sentiment  \n",
       "0                     -1  \n",
       "1                     -1  \n",
       "2                     -1  \n",
       "3                      1  \n",
       "4                      1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_df.head()\n",
    "\n",
    "# print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
